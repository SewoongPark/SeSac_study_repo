## **TIL**
* **머신러닝과 딥러닝의 차이?**
    * 머신러닝: 정형데이터 분석
    * 딥러닝: 비정형 데이터 포함 분석

* 머신러닝을 사용하지 않는 이상 대부분은 분류 task
* **오차 계산에서의 차이점**
    * 고전적인 회귀 분석 머신러닝: $f(x)$ 계산식이 고정이어서 오차 계산 하지 않음
    * 딥러닝: $w, b$를 무작위로 만들어서 오차를 계산하고, 오차가 최소가 되도록 경사하강(미분, Gradient descent)하여 오차 계산하는 과정 반복
        
        > * 경사하강법: 딥러닝 알고리즘 학습 시 목표는 예측값과 정답값 간의 차이인 손실 함수의 크기를 최소화시키는 파라미터를 찾는 것

        <img src = "https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fd0DKa4%2FbtrCKjA6dHH%2FKd6HN8fi77eYBUOkQQd0q1%2Fimg.png" style = "width: 30%;">

### **훈련 데이터와 테스트 데이터**

<img src = "https://velog.velcdn.com/images%2Frcchun%2Fpost%2Ffc232e11-de18-4b8f-8028-34378f8673f2%2Fimage.png" style = "width: 50%">

* **훈련 데이터(Training Data):**

    > * 훈련 데이터는 **모델을 학습하는 데 사용**됩니다.
    > * 모델이 예측하고자 하는 목표 변수(타겟 변수)와 그에 대한 입력 변수(특성)들이 포함됩니다.
    > * 일반적으로 훈련 데이터는 모델이 학습하는 데 충분한 다양성과 양을 가지고 있어야 합니다.
    > * 훈련 데이터는 모델이 일반화(generalization)하는 데 도움이 되는 다양한 패턴과 특징을 포착해야 합니다.

* **테스트 데이터(Test Data):**

    > * 테스트 데이터는 모델이 학습한 후에 모델의 **성능을 평가**하는 데 사용됩니다.
    > * 테스트 데이터는 훈련 데이터와 유사하게 구성되어 있지만 모델이 **이전에 본 적이 없는 새로운 데이터**로 구성됩니다.
    > * 테스트 데이터를 사용하여 모델의 예측을 평가하고 모델의 성능을 측정합니다.
    > * 모델 $w, b$의 오차가 작은지, 일치 확률이 높은지 확인

* **검증용 데이터(Validation Data):**
    > * 모델의 **성능을 조정**하기 위한 용도입니다.
    > * 과적합이 되고 있는지 판단하거나 하이퍼파라미터의 조정을 위한 용도입니다.
    > * 훈련용 데이터로 훈련을 모두 시킨 모델은 검증용 데이터를 사용하여 **정확도를 검증하며 하이퍼파라미터를 튜닝(tuning)** 합니다. 훈련데이터에서 경사하강(오차역전파)을 통해 오차를 줄일 때 $w, b$를 넣고 $y$값의 오차를 확인

* **비유하자면 훈련 데이터는 문제지, 검증 데이터는 모의고사, 테스트 데이터는 실력을 최종적으로 평가하는 수능 시험이라고 볼 수 있다.**
* 검증 데이터와 테스트 데이터를 나눌 만큼 데이터가 충분하지 않다면 k-폴드 교차 검증이라는 또 다른 방법을 사용

    > * k-fold 교차 검증은 데이터를 k개의 서브셋(또는 폴드)으로 나누고, 각각의 폴드를 한 번씩 테스트 세트로 사용하여 모델을 k번 평가합니다.
    > * k-1개의 폴드를 합쳐서 훈련 세트로 사용하고, 나머지 1개의 폴드를 테스트 세트로 사용합니다.
    > * 이 과정을 k번 반복하여 각 폴드가 한 번씩 테스트 세트로 사용되도록 합니다.
    > * 각 폴드의 성능을 평균하여 모델의 최종 성능을 계산합니다. 

* **훈련과 테스트 데이터를 나누는 적절한 비율**은 다음의 요소에 의해 결정됨
    * 데이터의 양, 모델의 복잡성, 데이터의 품질, 모델 평가의 목적, 교차 검증 사용 여부
    
    * 일반적으로 60%~80%의 데이터를 훈련에 사용
    * 실험을 통해 여러 비율을 시도하고 모델의 성능을 평가하여 최적의 비율을 정하는 것이 좋음
     * 참고: `stratify`
        > * `stratify`는 데이터를 나눌 때 클래스(또는 레이블) 간의 분포를 유지하는 방법을 의미합니다. 
        > * 특히, 기계 학습에서 주로 사용되며, 데이터를 나눌 때 각 클래스의 비율을 유지하여 훈련 및 테스트 세트를 만듭니다. 
        > * 특히, 분류 문제에서 클래스가 불균형하게 분포되어 있는 경우에는 모델이 불균형한 클래스에 대해 더 잘 학습하도록 하는 데 도움이 될 수 있습니다.

* **알아두기**
> * 훈련 데이터는 fit하지만 테스트 데이터는 fit하지 않음. 

> * Scaling(정규화)할 때 훈련 데이터로 맞추는 것이 아니라 테스트 데이터로 맞춤
* **공식 알아두기: Min-max Scaler**
    * $xscaled​ = \frac {x−min(x)} {max(x)−min(x)}​$ <br>
* 공부 자료: <a>https://wikidocs.net/84617</a> 

#### **활성화 함수**
* 활성화 함수(Activation Function)은 인공 신경망의 각 뉴런에서 입력 신호의 가중치 합을 출력으로 변환하는 함수입니다.
    * 입력 데이터 x에 대해 사용자가 지정한 활성화 함수로 계산
    
    > 1. **시그모이드 함수** - 출력 범위: 0 ~ 1
    > 2. **하이퍼볼릭 탄젠트 함수** - 출력 범위: -1 ~ 1
    > 3. **ReLu 함수** - 출력 범위: 입력이 양수일 경우 그대로 출력, 음수일 경우 0으로 출력
    > 4. **Softmax 함수** - 입력 값을 정규화하여 각 클래스에 대한 확률을 출력

* 학습 시 오차를 줄여나가는 미분 방정식이 경사하강법
* **가중치와 편향**
    * 가중치(weight)와 편향(bias)은 인공 신경망에서 각각 입력 신호와 함께 곱해지고 더해져서 출력을 생성하는 데 사용되는 파라미터입니다.
 
       > * **가중치(Weight):**
       >      * 가중치는 각 입력 신호의 중요도를 나타냅니다.
       >      * 입력과 가중치의 곱은 해당 입력의 영향력을 조절하는 역할을 합니다.
       >      * 각 뉴런의 가중치는 학습 과정에서 조정되어 데이터에 대한 적절한 표현을 학습합니다.
       >  
       >  * **편향(Bias):**
       >     * 편향은 각 뉴런이 얼마나 쉽게 활성화될지를 제어합니다. 즉, 모든 입력이 0인 경우에도 뉴런이 활성화되도록 합니다.
       >     * 편향은 입력이 없을 때 출력이 어떤 값이 되어야 하는지를 결정합니다. 
       >     * 입력에 대한 가중합이 0일 때, 편향은 뉴런의 출력을 조정합니다.
---
* ### Mnist dataset 실습
**10개의 라벨 중에서 분류하는 다항 분류 task**
  * 반드시 원핫인코딩 해주어야 함
  * loss함수를 `sparse_Categorical_crossentrophy`로 지정해줄 시 알아서 원핫인코딩 함
* **모델 구조 및 결과 시각화**
* **모델 훈련 및 평가**
* **모델 저장**
  * weight값만 저장하거나 모델 전체를 저장할 수 있음
* **학습한 모델로 새로운 데이터 예측하기**
