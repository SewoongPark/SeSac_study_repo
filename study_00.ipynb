{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMO4m9HOOtY409UJLji9pU9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SewoongPark/SeSac_study_repo/blob/main/study_00.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TIL**\n",
        "\n",
        "### **전이 학습(Transfer Learning)**\n",
        "* 전이 학습은 다양한 사전 훈련된 모델이 있는 작업에 유용합니다. 예를 들어, 널리 사용되는 많은 CNN(컨벌루션 신경망)은 1,400만 개 이상의 영상과 수천 개의 영상 클래스를 포함하는 ImageNet 데이터셋에 대해 사전 훈련되었습니다. <br>만약 여러분이 정원의 꽃 영상(또는 ImageNet 데이터셋에 포함되지 않은 영상)을 분류해야 하는데 꽃 영상 수가 제한적인 경우, SqueezeNet 신경망에서 계층과 가중치를 전이하고 최종 계층을 교체한 후 보유한 영상으로 모델을 재훈련시킬 수 있습니다.<br>\n",
        "이 접근법으로 여러분은 전이 학습을 통해 더 짧은 시간에 더 높은 모델 정확도를 달성할 수 있습니다.\n",
        "<img src = \"https://kr.mathworks.com/discovery/transfer-learning/_jcr_content/mainParsys/band/mainParsys/lockedsubnav/mainParsys/columns_1336656927/a8810b41-e0c1-4c16-91f9-10b6a66488fe/image_copy_1488534355.adapt.full.medium.gif/1705253487834.gif\" style=\"width: 50%;\">\n",
        "\n",
        "* **모델 종류: Resnet 50**\n",
        "> * ResNet-50은 딥러닝에서 널리 사용되는 컨볼루션 신경망 중 하나로, Microsoft Research에서 개발되었습니다. \"ResNet\"은 \"Residual Network\"의 줄임말로, 네트워크의 깊이를 키우는 동안 그라디언트 소실 문제를 해결하기 위한 특별한 구조를 가지고 있습니다\n",
        "<img src = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/resnet_architecture.png\">\n",
        "\n",
        "* 우수 활용 사례: tensorflow Airbnb\n",
        "  * 방 유형을 분류해서 사진을 업로드해야하는 상황(주방이냐, 거실이냐 등)\n",
        "  * 데이터 라벨링을 위해 하이브리드(사람 검수 + 자동화)방법 도입\n",
        "  * 사람들이 인터넷에 업로드한 사진과 설명을 사용하여 라벨링에 이용\n",
        "  > * 주방 사진만 가져오기 위해서 SQL로 필터링\n",
        "  \n",
        "    ``` SQL\n",
        "    WHERE LOWER(caption) NOT LIKE \"%livingroom%\"\n",
        "    WHERE LOWER(caption) NOT LIKE \"%bed%\"\n",
        "    WHERE LOWER(caption) NOT LIKE \"%bath%\"\n",
        "    ```\n",
        "\n",
        "* #### ResNet-50 모델의 특징\n",
        "* **깊이:**<br>\n",
        " > ResNet-50은 50개의 레이어로 구성됩니다. 이는 이전의 네트워크 아키텍처인 VGG나 AlexNet보다 더 깊은 네트워크입니다.\n",
        "* **Residual connections:** <br>\n",
        "> ResNet의 핵심 아이디어는 잔차 학습(Residual Learning)입니다. 각 블록에서 입력이 출력에 직접 추가되는 잔차 연결(residual connection)이 있습니다. 이를 통해 네트워크가 더 쉽게 학습하고 최적화할 수 있습니다.\n",
        "* **Bottleneck 구조:** <br>\n",
        "  > ResNet-50은 \"bottleneck\" 구조를 사용합니다. 이는 1x1, 3x3, 1x1 컨볼루션 레이어로 구성된 블록으로, 연산량을 줄이고 효율적으로 학습을 진행할 수 있도록 도와줍니다.\n",
        "\n",
        "* **Pre-trained 모델:** <br>\n",
        "> ResNet-50은 대규모 이미지 데이터셋(ImageNet)에 대해 사전 훈련된 가중치를 가진 모델로 제공됩니다. 이를 통해 전이 학습(transfer learning)을 사용하여 다양한 컴퓨터 비전 작업에 쉽게 적용할 수 있습니다.\n",
        "\n",
        "* **AlexNet**\n",
        "\n",
        "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbxzopl%2FbtqO7hUvidV%2FSTksKg4JDu6O34PpbVFxl1%2Fimg.png\" style = \"width:70%\">\n",
        "\n",
        "* ConV층에서 Pooling은 지난 강의에서 보통 max Pooling으로 receptive field에서 지정한 구간내의 max값을 취한다고 했었죠? 그러므로 맥스풀링에서는 파라미터가 없습니다.\n",
        "* 그렇게 ConV layer를 거치면 이 feature map들을 flatten해주므로 4096개 뉴런이 있는 FC layer로 진입합니다.\n",
        "* FC층에서 FC6,7 layer에서는 가장 흔히 쓰는 Relu함수를 비선형 함수로 이용합니다\n",
        "* 그리고 출력층 FC8에서는 1000개의 class score를 뱉기 위한 softmax함수를 이용합니다.\n",
        "* 2개의 Normalization층은 실험 결과, 크게 효과가 없다고 밝혀져서 현재는 잘 사용하지 않지만 AlexNet에서는 쓰였습니다.\n"
      ],
      "metadata": {
        "id": "C74Q4s_oK6nq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cj8utYAjHcVs"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ]
}